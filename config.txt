本项目参考自崔庆老师的作品：https://github.com/Python3WebSpider/CookiesPool
在开始这个项目之前，你需要找到一些你要登陆网站的账号信息
然后需要安装相关的库文件：Flask、Redis、selenium、Chrome或者PhantomJS、PIL
在这个CookiesPool中，主要有以下几个模块组成：
一、存储模块；存储每个账号的用户名、密码以及Cookies（这里采用的是redis的hash表来存储）
    1.编写一个存储模块，用redis中的hash来存储账号、密码以及Cookies这样可以很好的达到去重的效果
    2.由于Cookies要做到可扩展，这里Hash可以做二级分类，比如：知乎就可以保存为：accounts:zhihu,cookies:zhihu这样来作为键存储
    3.用到了redis的hash表的相关操作来定义一些通用的方法，方便后面调用
二、生成模块；把账号存到redis之后，通过生成模块来生成新的Cookies
    1.这里结合模拟登陆模块，在模拟登陆成功之后，生成Cookie并保存到数据库中
    2.原理：先获取到数据库中的hash账号信息,看看账号的hash比cookie中的账号信息，然后进行对比，将剩余的账号进行遍历并生成cookie
    3.登陆成功并成功获取到cookie就将cookie通过存储模块中定义的方法，将其加入cookie的hash表中
三、检测模块；需要定时的检测数据库中的Cookies，把不能登陆的Cookies从库中删除
    1.原理：先遍历cookie的hash表中所有的cookie，同时设置好对应的检测连接，用一个个cookie去请求这个连接，如果请求成功，则表示该cookie
    有效，如果失败，则表示失效或者格式错误，将其从cookie的hash中删除，生成模块会定时检测这两个表中的信息，然后再生成新的cookie
    2.为了扩展性，这里定义了一个检测器的父类，在子类中继承父类并需要重写test()方法即可
四、接口模块；这里采用的Falsk框架来编写的一个接口，拿到随机的Cookie
    采用Falsk框架来编写一个获取cookie的接口
五、模拟登陆模块，编写模拟登陆的程序，以供检测和生成模块使用
    编写破解验证码程序，拿到模版，进行对比，每台电脑的配置不一样，虽然此项目里面有一些模版，但仅仅作为示例
       最好重新生成模版，这样的匹配成都才能达到要求，才能实现正确的模拟拖动（亲自试过）
六、调度模块
    这里定义一个调度模块，用来采用多进程的方式开启各个模块，各个模块之间的运行互不影响


